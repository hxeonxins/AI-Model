# 인공지능모델링_2111_심현진 보고서

> 이 파일을 PDF로 변환해 제출하세요. (폰트: 맑은 고딕/나눔고딕, 본문 11pt, 줄간격 160%)

## 1. 프로젝트 소개
- **주제:** 교통수단 이미지 분류 (CIFAR-10의 비행기/자동차/트럭 3클래스)
- **선정 이유:** 공개 데이터로 즉시 실험 가능, 클래스 간 시각적 차이가 뚜렷해 학습 효과와 실습 적합성 높음.
- **실생활 활용:** 간단한 교통수단 인식, 교통량 분석, 드론·CCTV 객체 분류 선행 모델로 활용 가능.
- **데이터 수집 과정:** Keras 내장 CIFAR-10 다운로드 → 3개 클래스만 필터링 → 8:2로 학습/검증 분리 → 리사이즈(96x96), 정규화(0~1), 증강(RandomFlip/Rotation/Brightness) 적용.

## 2. 모델 설계 및 구현
- **모델 아키텍처**
  - *기본 CNN*: `Conv(32)-MaxPool-Conv(64)-MaxPool-Conv(128)-GAP-Dropout(0.3)-Dense(softmax)`
  - *전이학습*: `ResNet50(Imagenet, top 제거, 동결/부분 미세조정) - GAP - Dropout(0.3) - Dense(softmax)`
  - 활성함수: 합성곱에 ReLU, 출력에 Softmax → 다중 클래스 분류에 적합.
- **데이터 전처리**
  - 리사이즈: 96x96 (모델/전이학습 호환성)
  - 정규화: `float32 / 255.0`
  - 증강: RandomFlip, RandomRotation(0.1), RandomBrightness(0.1)
- **학습 설정**
  - 손실: SparseCategoricalCrossentropy
  - 옵티마이저: Adam(기본), RMSprop/SGD 옵션
  - 기본 배치/에포크: 64 / 15 (필요 시 조정, 긴 학습 필요 시 20+권장)
  - 콜백: EarlyStopping(patience=5, val_accuracy), ReduceLROnPlateau, ModelCheckpoint, TensorBoard
  - 데이터 샘플링: `sample_fraction`으로 리허설/빠른 실험 수행 가능

## 3. 실험 결과 및 분석
- **실험 설정**: 학습/검증 8:2, 클래스 3개, 입력 96x96
- **비교표** (학습 후 수치 기입, `logs/experiments.csv` 참고)

| 실험 번호 | 모델 구조 | Augmentation | Optimizer/LR | Accuracy | Loss | 특이사항 |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | CNN (샘플런) | None | Adam / 1e-3 | 0.314 | 1.096 | 데이터 10%, 1 epoch, 64x64, 빠른 리허설 |
| 2 | ResNet50 (파인튜닝 20층) | Flip + Rotation + Brightness | Adam / 5e-4 | 0.538 | 1.019 | 데이터 30%, 3 epoch, 64x64, 빠른 파인튜닝 |
| 3 | CNN + Dropout | Flip + Rotation + Brightness | Adam / 7e-4 | 0.349 | 1.098 | 데이터 50%, 3 epoch, 64x64 |
| 4 | ResNet50 (동결) | Flip + Rotation + Brightness | Adam / 5e-4 | 0.328 | 1.099 | 데이터 50%, 3 epoch, 64x64, 베이스 전이 |
| 5 | ResNet50 (파인튜닝 20층) | Flip + Rotation + Brightness | Adam / 3e-4 | 0.478 | 1.033 | 데이터 50%, 3 epoch, 64x64, 저 LR 파인튜닝 |
| 6 | ResNet50 (파인튜닝 40층) | Flip + Rotation + Brightness | Adam / 4e-4 | 0.574 | 0.896 | 데이터 40%, 3 epoch, 96x96, 최신 실험 |
| 7 | ResNet50 (GPU 파인튜닝) | Flip + Rotation + Brightness | Adam / 2e-4 | 0.809 | 0.494 | 데이터 100%, 30 epoch, 160x160, Colab T4 |

- **TensorBoard 캡처**: `logs/resnet_20251211-101617`(로컬)과 `logs/resnet_20251211-062930`(Colab GPU) run을 열어 Train vs Val Loss/Acc 그래프 캡처해 첨부.
- **성능 개선 과정 요약**
  - 증강(RandomFlip/Rotation/Brightness) → 과적합 감소, 일반화 향상
  - ReduceLROnPlateau/Adam → 학습 후반 손실 감소 안정화
  - 전이학습 → 기본 CNN 대비 초기 정확도 상승
  - 96x96 입력 + 더 깊은 파인튜닝(40층) → 현재 최고 Val Acc 57.4% (여전히 목표 95% 미달, 추가 장시간 학습 및 GPU 필요)

## 4. 결론 및 한계
- **성과 요약:** 교통수단 3클래스 분류 모델 구현, CNN/전이학습 비교, 최소 3가지 이상 최적화 적용.
- **최종 모델 성능:** ResNet50 파인튜닝(로컬: 데이터 40%, 96x96, 3 epoch) Val Acc 0.574 / Loss 0.896; Colab T4(데이터 100%, 160x160, 30 epoch) Val Acc 0.809 / Loss 0.494.
- **목표 달성 여부:** 여전히 95% 목표 미달. GPU에서 더 긴 학습(40 epoch+), 입력 160~192, 강한 증강/label smoothing 필요.
- **한계/개선:** CIFAR-10 해상도 및 도메인 한계, 학습 시간 부족 → 도메인 데이터로 재학습, 에포크 확장, cosine warmup·mixup 등 추가 실험 제안.
- **오분류 사례:** TensorBoard의 misclass 예측 시각화 또는 Grad-CAM 등(추가 캡처 가능).

## 5. 재현 방법 (보고서에 간단히 첨부)
```bash
pip install -r requirements.txt
python main.py --model cnn --epochs 20 --batch_size 64 --learning_rate 1e-3
python main.py --model resnet --epochs 15 --learning_rate 5e-4 --fine_tune True --base_trainable_layers 20
# 빠른 샘플런 (데이터 10%만 사용)
python main.py --model cnn --epochs 1 --batch_size 256 --image_size 64 --augmentations none --sample_fraction 0.1
# 실험 배치 실행 및 CSV 저장
python experiments.py
# TensorBoard
tensorboard --logdir logs
```

### 현재 실행된 샘플런 요약
- 커맨드(리허설1): `python main.py --model cnn --epochs 1 --batch_size 256 --image_size 64 --augmentations none --sample_fraction 0.1`
- 결과: Val accuracy 0.3139, Val loss 1.0957
- 로그: `logs/cnn_20251210-130630`
- 체크포인트: `saved_models/cnn_20251210-130630/model.keras`
- 최종 모델: `saved_models/model_final/cnn_final.keras`

- 커맨드(리허설2): `python main.py --model resnet --epochs 3 --learning_rate 5e-4 --fine_tune True --base_trainable_layers 20 --batch_size 128 --image_size 64 --augmentations flip,rotation,brightness --sample_fraction 0.3`
- 결과: Val accuracy 0.5380, Val loss 1.0186
- 로그: `logs/resnet_20251210-161141`
- 체크포인트: `saved_models/resnet_20251210-161141/model.keras`
- 최종 모델: `saved_models/model_final/resnet_final.keras`

- 커맨드(최신 96x96 실험): `.venv/bin/python main.py --model resnet --epochs 3 --learning_rate 4e-4 --fine_tune True --base_trainable_layers 40 --batch_size 128 --image_size 96 --augmentations flip,rotation,brightness --sample_fraction 0.4`
- 결과: Val accuracy 0.5736, Val loss 0.8958
- 로그: `logs/resnet_20251211-101617`
- 체크포인트: `saved_models/resnet_20251211-101617/model.keras`
- 최종 모델: `saved_models/model_final/resnet_final.keras` (최근 실험으로 갱신)

> 현재 최고 성능은 57.4%(3 epoch)로 95% 목표에는 미달입니다. GPU에서 20~30 epoch, 전체 데이터 사용, 입력 128x128 이상, 강한 증강/label smoothing 등을 적용해 추가 학습이 필요합니다.

### 추가 실험 (Colab GPU)
- 커맨드(160x160, T4): `python main.py --model resnet --epochs 30 --learning_rate 2e-4 --fine_tune True --base_trainable_layers 140 --batch_size 128 --image_size 160 --augmentations flip,rotation,brightness --sample_fraction 1.0`
- 결과: Val accuracy 0.8094, Val loss 0.4940
- 로그: `logs/resnet_20251211-062930`
- 체크포인트: `saved_models/resnet_20251211-062930`
- 최종 모델: `saved_models/model_final/resnet_final.keras` (Colab 결과로 덮어씀)

> GPU 30epoch 기준 최고 성능 80.9%로, 95% 목표까지는 추가로 40epoch 이상, 더 큰 입력(160~192), label smoothing/mixup 등 강한 증강이 필요합니다.
